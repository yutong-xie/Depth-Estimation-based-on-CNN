<<<<<<< Updated upstream
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "import os\n",
    "os.chdir(\"gdrive/My Drive/Depth_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import PIL\n",
    "\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from nyu_dataloader import LoadData, NYUDataset\n",
    "from model import CoarseNetwork, FineNetwork\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std= [0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.Resize((304,228)),\n",
    "            transforms.CenterCrop((304,228)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "#             transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "            transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.Resize((304,228)),\n",
    "            transforms.CenterCrop((304,228)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "ds_train = LoadData('train')\n",
    "ds_val = LoadData('val')\n",
    "ds_test = LoadData('test')\n",
    "\n",
    "\n",
    "train_data = NYUDataset(ds_train, train_transform)\n",
    "val_data = VocDataset(ds_val, test_transform)\n",
    "test_data = VocDataset(ds_test, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 60\n",
    "test_frequency = 5\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=False,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
=======
{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"h0R_WVgISTy6"},"source":["# Download Files"]},{"cell_type":"code","metadata":{"id":"a3rDW847b3Cx"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir(\"gdrive/My Drive/Depth_Project\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_m1sLAaBd-_y"},"source":["# Load Packages"]},{"cell_type":"code","metadata":{"id":"hTulXzfYb3C3"},"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import PIL\n","\n","from torchvision import transforms\n","from sklearn.metrics import average_precision_score\n","from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","# from nyu_dataloader import LoadData, NYUDataset\n","# from model import Net\n","# from metrics import Metrics\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jdffZ-jRiuvE"},"source":["# Load Dataset \n"]},{"cell_type":"code","metadata":{"id":"sKvE9wKTiu3K"},"source":["import h5py\n","import numpy as np\n","import random\n","import torch\n","import torch.utils.data as data\n","from torchvision import transforms, utils\n","from PIL import Image\n","\n","def LoadData(mode):\n","    path = 'dataset/nyu_depth_v2_labeled.mat'\n","    dataset = h5py.File(path, 'r')\n","\n","    images= dataset[\"images\"]\n","    depths = dataset[\"depths\"]\n","\n","    images = np.array(images)\n","    depths = np.array(depths)\n","\n","    train, val, test = 1000, 250, 200\n","\n","    if mode == \"train\":\n","        image = images[:train, :]\n","        depth = depths[:train, :]\n","        \n","    elif mode == \"val\":\n","        image = images[train:train + val, :]\n","        depth = depths[train:train + val, :]\n","    elif mode == \"test\":\n","        image = images[train + val:, :]\n","        depth = depths[train + val:, :]\n","        \n","\n","    print(\"Total %s samples: %d\" % (mode, len(image)))\n","    print(\"Image sample size:\", image[0].shape)\n","    return (image, depth)\n","\n","# ImageNet \n","mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n","# NYU Dataset \n","images_mean = [109.31410628 / 255, 109.31410628 / 255, 109.31410628 / 255]\n","images_std = [76.18328376 / 255, 76.18328376 / 255, 76.18328376 / 255]\n","\n","\n","class NYUDataset(data.Dataset):\n","    def __init__(self, dataset, transform = None):\n","        self.images = dataset[0]\n","        self.depths = dataset[1]\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        # image size: 3, 640, 480 (3, W, H)\n","        # depths size: 648, 480\n","        image = self.images[index]\n","        depth = self.depths[index]\n","\n","        # Transpose the image to H, W, 3\n","        image = np.transpose(image, (2, 1, 0))\n","        depth = np.transpose(depth, (1, 0))\n","\n","        image = Image.fromarray(image)\n","        depth = Image.fromarray(depth)\n","\n","        if self.transform:\n","            seed = random.randint(0, 2**32)\n","            random.seed(seed)\n","            image = self.transform(image)\n","            random.seed(seed)\n","            depth = self.transform(depth)\n","\n","        # Resize depth image \n","        depth = transforms.Resize((74, 55))(depth)\n","\n","        # Transform to Tensor \n","        image = transforms.ToTensor()(np.array(image))\n","        depth = transforms.ToTensor()(np.array(depth))\n","\n","        # Normalize the images\n","        # image = transforms.Normalize(images_mean, images_std)(image)\n","\n","        return image, depth\n","        \n","    def __len__(self):\n","        return len(self.images)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5E_fgzHi3II"},"source":["# # Load the dataset \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# not matching paper \n","train_transform = transforms.Compose([\n","            transforms.Resize((320,240)),\n","            transforms.CenterCrop((304,228)),\n","            transforms.RandomHorizontalFlip(), # by default 0.5\n","            transforms.RandomRotation(5, resample=PIL.Image.BILINEAR)\n","            \n","        ])\n","\n","\n","test_transform = transforms.Compose([\n","            transforms.Resize((304,228)),\n","            transforms.CenterCrop((304,228))\n","        ])\n","\n","ds_train = LoadData('train')\n","ds_val = LoadData('val')\n","ds_test = LoadData('test')\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9YvPuKFjBwo"},"source":["\n","train_data = NYUDataset(ds_train, train_transform)\n","val_data = NYUDataset(ds_val, test_transform)\n","test_data = NYUDataset(ds_test, test_transform)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbCXD-o7jEoY"},"source":["batch_size = 32 # from paper\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_data,\n","                                               batch_size=batch_size, \n","                                               shuffle=True,\n","                                               num_workers=1)\n","\n","val_loader = torch.utils.data.DataLoader(dataset=val_data,\n","                                               batch_size=batch_size, \n","                                               shuffle=True,\n","                                               num_workers=1)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_data,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksDqy4_cS-lR"},"source":["# Load Model"]},{"cell_type":"code","metadata":{"id":"8vUe7vyeS9mC"},"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","from torch import optim\n","import numpy as np\n","\n","\n","class CoarseNetwork(nn.Module):\n","    def __init__(self):\n","        super(CoarseNetwork, self).__init__()        \n","        self.coarse1 = nn.Sequential(\n","            nn.Conv2d(3, 96, 11, stride = 4),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2)\n","        )\n","        self.coarse2 = nn.Sequential(\n","            nn.Conv2d(96, 256, 5, padding = 2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2)\n","        )\n","        self.coarse3 = nn.Sequential(\n","            nn.Conv2d(256, 384, 3, padding = 1),\n","            nn.ReLU()\n","        )\n","        self.coarse4 = nn.Sequential(\n","            nn.Conv2d(384, 384, 3, padding = 1),\n","            nn.ReLU()\n","        )\n","        self.coarse5 = nn.Sequential(\n","            nn.Conv2d(384, 256, 3, stride = 2),\n","            nn.ReLU()\n","        )\n","        self.coarse6 = nn.Sequential(\n","            nn.Linear(8 * 6 * 256, 4096),\n","            nn.ReLU(),\n","            nn.Dropout()\n","        )\n","        self.coarse7 = nn.Sequential(\n","            nn.Linear(4096, 74 * 55)\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.coarse1(x)\n","        x = self.coarse2(x)\n","        x = self.coarse3(x)\n","        x = self.coarse4(x)\n","        x = self.coarse5(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.coarse6(x)\n","        x = self.coarse7(x)\n","        x = x.view(x.size(0), 1, 74, 55)\n","        return x\n","      \n","\n","class FineNetwork(nn.Module):\n","    def __init__(self):\n","        super(FineNetwork, self).__init__()\n","        self.fine1 = nn.Sequential(\n","            nn.Conv2d(3, 63, 9, stride = 2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2)\n","        )\n","        self.fine2 = nn.Sequential(\n","            nn.Conv2d(64, 64, 5, padding = 2),\n","            nn.ReLU()\n","        )\n","        self.fine3 = nn.Sequential(\n","            nn.Conv2d(64, 1, 5, padding = 2)\n","        )\n","\n","    def forward(self, x, coarse_output):\n","        x = self.fine1(x)\n","        x = torch.cat((x, coarse_output), dim = 1)\n","        x = self.fine2(x)\n","        x = self.fine3(x)\n","        return x\n","\n","    \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"toN8x4pJTEG0"},"source":["# Load loss function"]},{"cell_type":"code","metadata":{"id":"3Uj_oksoTHcp"},"source":["class Train_Loss(nn.Module):\n","    def __init__(self, param = 0.5):\n","        super(Train_Loss, self).__init__()\n","        self.param = param \n"," \n","    def forward(self, pred, target):\n","        # mask out zero values and invalid regions\n","        # mask = target > 0\n","        mask = (target == 0) | (target == target.max()) | (target == target.min())\n","        diff = pred[~mask] - torch.log(target[~mask])\n","        # diff = pred[mask] - torch.log(target[mask])\n","        \n","        # the lambda parameter is set to 0.5\n","        loss = torch.mean(diff**2) - self.param * torch.pow(torch.mean(diff), 2)\n","        # loss = torch.mean(dist ** 2) - 0.5 / ((torch.numel(dist)) ** 2) * (torch.sum(dist) ** 2) \n","        return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"401W7hjAxLny"},"source":["## Plot Loss\n"]},{"cell_type":"code","metadata":{"id":"35Jfrw0qxOoQ"},"source":["def plot_loss(train_loss, val_loss):\n","    plt.plot(train_loss, label='train losses')\n","    plt.plot(val_loss, label='valid losses')\n","    plt.title(\"Losses\")\n","    plt.xlabel(\"Training Epochs\")\n","    plt.ylabel(\"Losses\")\n","    plt.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mTrptye0TJ-7"},"source":["# Load Metrics "]},{"cell_type":"code","metadata":{"id":"1W80_IhbTJbu"},"source":["def Metrics_Calculate(pred, target):\n","    pred_log = pred\n","    pred = torch.exp(pred)\n","    # calculate threshold: % of y with y_pred/y_target < threshold\n","    ratio = torch.max(pred / target, target / pred)\n","    total = torch.numel(ratio)\n","    t1 = torch.numel(ratio[ratio < 1.25]) / total\n","    t2 = torch.numel(ratio[ratio < 1.25**2]) / total\n","    t3 = torch.numel(ratio[ratio < 1.25**3]) / total\n","\n","    t1 /= total\n","    t2 /= total\n","    t3 /= total\n","\n","    # calculate abs relative difference\n","    abs_error = torch.abs(pred-target) / target\n","    abs_error = torch.mean(abs_error)\n","\n","    # calculate squared relative difference\n","    squared_error = torch.pow(pred - target, 2) / target\n","    squared_error = torch.mean(squared_error)\n","\n","    # calculate RMSE(linear)\n","    rmse_linear = torch.pow(pred - target, 2)\n","    rmse_linear = torch.sqrt(torch.mean(rmse_linear))\n","\n","    # calculate RMSE(log)\n","    rmse_log = torch.pow(pred_log - torch.log(target), 2)\n","    rmse_log = torch.sqrt(torch.mean(rmse_log))\n","\n","    return t1, t2, t3, abs_error, squared_error, rmse_linear, rmse_log\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sqmurj2DcS_z"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"n_njaNoouYml"},"source":["load_network = {'coarse':False, 'fine':False}\n","load_network_path = {'coarse':'models/coarse_net.pt', 'fine':'models/fine_net.pt'}\n","\n","\n","# net = Net().to(device)\n","net = {'coarse': CoarseNetwork().to(device), 'fine':FineNetwork().to(device)}\n","\n","# load saved model\n","for mode in ['coarse', 'fine']:\n","  if load_network[mode] and load_network_path[mode] is not None:\n","    print('Loading network from {}'.format(load_network_path[mode]))\n","    net.load_state_dict(torch.load(load_network_path[mode]))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rpNFLJoSy_OL"},"source":[" param =0.5 # 0 1\n","# # learning_rate = {'coarse': [0.001,0.001,0.001,0.001,0.001,0.1,0.1], 'fine':[0.01,0.1,0.01]}\n","learning_rate = 0.001\n","num_epochs = {'coarse':30, 'fine':30}\n","\n","criterion = Train_Loss(param)\n","\n","optimizer = {'coarse': torch.optim.SGD(net['coarse'].parameters(), lr = 0.001, momentum=0.9, weight_decay= 5e-4),\n","             'fine':torch.optim.SGD(net['fine'].parameters(), lr = 0.001, momentum=0.9, weight_decay= 5e-4)}\n","\n","# optimizer = {'coarse': torch.optim.Adam(net['coarse'].parameters(), lr = 0.001),\n","#              'fine':torch.optim.Adam(net['fine'].parameters(), lr = 0.001)}\n","\n","optimizer = {}\n","optimizer['coarse'] = torch.optim.SGD([ \n","                                       {'params': net['coarse'].coarse1.parameters(), 'lr': 0.001}, {'params': net['coarse'].coarse2.parameters(), 'lr': 0.001},\n","                                       {'params': net['coarse'].coarse3.parameters(), 'lr': 0.001}, {'params': net['coarse'].coarse4.parameters(), 'lr': 0.001},\n","                                       {'params': net['coarse'].coarse5.parameters(), 'lr': 0.001}, {'params': net['coarse'].coarse6.parameters(), 'lr': 0.1},\n","                                       {'params': net['coarse'].coarse7.parameters(), 'lr': 0.1}\n","                                       ], lr=0.001, momentum=0.9, weight_decay= 5e-4)\n","\n","optimizer['fine'] = torch.optim.SGD([\n","                                     {'params': net['fine'].fine1.parameters(), 'lr': 0.001},                                  \n","                                     {'params': net['fine'].fine2.parameters(), 'lr': 0.01},                                   \n","                                     {'params': net['fine'].fine3.parameters(), 'lr': 0.001}                                    \n","                                     ], lr=0.001, momentum=0.9, weight_decay= 5e-4)\n","\n","# optimizer = {}\n","# optimizer['coarse'] = torch.optim.Adam([ \n","#                                        {'params': net['coarse'].coarse1.parameters(), 'lr': 0.001}, {'params': net['coarse'].coarse2.parameters(), 'lr': 0.001},\n","#                                        {'params': net['coarse'].coarse3.parameters(), 'lr': 0.001}, {'params': net['coarse'].coarse4.parameters(), 'lr': 0.001},\n","#                                        {'params': net['coarse'].coarse5.parameters(), 'lr': 0.001}, {'params': net['coarse'].coarse6.parameters(), 'lr': 0.1},\n","#                                        {'params': net['coarse'].coarse7.parameters(), 'lr': 0.1}\n","#                                        ], lr=0.001)\n","\n","# optimizer['fine'] = torch.optim.Adam([\n","#                                      {'params': net['fine'].fine1.parameters(), 'lr': 0.001},                                  \n","#                                      {'params': net['fine'].fine2.parameters(), 'lr': 0.01},                                   \n","#                                      {'params': net['fine'].fine3.parameters(), 'lr': 0.001}                                    \n","#                                      ], lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8VAdheC6cLD7"},"source":["# Train Network"]},{"cell_type":"markdown","metadata":{"id":"hrUACyvx6Lwq"},"source":["### Train the coarse and fine network separately. \n","when training the ï¬ne network, we do not backpropagate through the coarse one. "]},{"cell_type":"code","metadata":{"id":"ABnohvqztvu4"},"source":["import time\n","\n","def train(mode, net, optimizer):\n","\n","    best_test_loss = float(\"inf\")\n","    val_loss_list = []\n","    train_loss_list = []\n","    # Loop over the dataset for multiple epochs\n","    for epoch in range(num_epochs[mode]):\n","        net[mode].train()\n","        running_loss = 0.0\n","        start_time = time.time()\n","\n","        print('\\nStarting epoch %d / %d' % (epoch + 1, num_epochs[mode]))\n","\n","        # For each mini-batch...      \n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer[mode].zero_grad()\n","            if mode == 'coarse':\n","                outputs  = net['coarse'](inputs) \n","            elif mode == 'fine':\n","                with torch.no_grad():\n","                    net['coarse'].eval()\n","                    coarse_outputs = net['coarse'](inputs)\n","                outputs = net['fine'](inputs, coarse_outputs.detach())\n","            \n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","\n","            optimizer[mode].step()\n","\n","            running_loss += loss.item()\n","\n","        running_loss /= len(train_loader)\n","        train_loss_list.append(running_loss)\n","\n","        # save model every 5 epochs\n","        # if epoch %5 == 4 and load_network_path is not None:\n","        #   torch.save(net[mode].state_dict(), load_network_path[mode])\n","\n","        # evaluate the network on the validation dataset \n","        with torch.no_grad():\n","            val_loss = 0.0\n","            net[mode].eval()                                  \n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                if mode == 'coarse':\n","                    outputs  = net['coarse'](inputs) \n","                elif mode == 'fine':\n","                    net['coarse'].eval()\n","                    coarse_outputs = net['coarse'](inputs)\n","                    outputs = net['fine'](inputs, coarse_outputs)\n","                loss = criterion(outputs,labels)\n","                val_loss += loss.item()\n","\n","            val_loss /= len(val_loader)\n","            val_loss_list.append(val_loss)\n","            # Metrics: t1, t2, t3, abs_error, squared_error, rmse_linear, rmse_log\n","            t1, t2, t3, abs_error, squared_error, rmse_linear, rmse_log =  Metrics_Calculate(outputs, labels)\n","            print(\"epoch:\", epoch + 1, \", training loss:\", running_loss, \"validation loss:\", val_loss)\n","            if epoch % 10 == 9:\n","                print(\"\\n------------Validation--------------\")\n","                print(\"Threshold < 1.25:\", t1)\n","                print(\"Threshold < 1.25^2:\", t2)\n","                print(\"Threshold < 1.25^3:\", t3)\n","                print(\"abs_relative_difference:\", abs_error.item())\n","                print(\"squared_relative_difference:\", squared_error.item())\n","                print(\"RMSE (linear):\", rmse_linear.item())\n","                print(\"RMSE (log):\", rmse_log.item())\n","                print(\"RMSE (log, scale inv.):\", val_loss)\n","                print(\"---------------------------------------\")\n","        \n","        # training_time = time.time() - start_time\n","        # print(\"Training time: %d min %d s\"% (training_time//60, training_time % 60))\n","    \n","    return net, train_loss_list, val_loss_list\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJY35mm82VyO"},"source":["net, train_losses, val_losses= train('coarse', net, optimizer)\n","plot_loss(train_losses, val_losses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RskqjHUjxe-j"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BpHLngKQE3ME"},"source":["### Train fine network "]},{"cell_type":"code","metadata":{"id":"WDmJ-S2Wnj3v"},"source":["net, train_losses, val_losses= train('fine', net, optimizer)\n","plot_loss(train_losses, val_losses)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRVh7MVVFCGh"},"source":["# Test the model and output samples \n"]},{"cell_type":"code","metadata":{"id":"AHcAvpC9FJgC"},"source":["test_loss = 0.0\n","for inputs, labels in test_loader:\n","    inputs, labels = inputs.to(device), labels.to(device)\n","\n","    net[\"coarse\"].eval()\n","    net[\"fine\"].eval()\n","\n","    with torch.no_grad():\n","        coarse_outputs = net['coarse'](inputs)\n","        fine_outputs = net['fine'](inputs, coarse_outputs)\n","\n","    loss = criterion(fine_outputs, labels)\n","    test_loss += loss.item()\n","\n","test_loss /= len(test_loader)\n","print(\"Test loss: \", test_loss)\n","t1, t2, t3, abs_error, squared_error, rmse_linear, rmse_log =  Metrics_Calculate(fine_outputs, labels)\n","print(\"\\n------------Validation--------------\")\n","print(\"Threshold < 1.25:\", t1)\n","print(\"Threshold < 1.25^2:\", t2)\n","print(\"Threshold < 1.25^3:\", t3)\n","print(\"abs_relative_difference:\", abs_error.item())\n","print(\"squared_relative_difference:\", squared_error.item())\n","print(\"RMSE (linear):\", rmse_linear.item())\n","print(\"RMSE (log):\", rmse_log.item())\n","print(\"RMSE (log, scale inv.):\", test_loss)\n","print(\"---------------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8w64uZkZzb1j"},"source":["torch.save(net['coarse'], 'models/coarse_model.pt')\n","torch.save(net['fine'], 'models/fine_model.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DbCeCRUICgd"},"source":["for i in range(4):\n","    rgb_image = transforms.ToPILImage()(inputs[i].cpu())\n","    \n","    coarse_output = torch.exp(coarse_outputs[i]).view(74, 55).cpu()\n","    fine_output = torch.exp(fine_outputs[i]).view(74, 55).cpu()\n","    depth_gt = labels[i].view(74, 55).cpu()\n","   \n","    plt.figure(figsize = (10, 20))\n","    plt.subplot(1, 4, 1)\n","    plt.title(\"Input Image\")\n","    plt.imshow(rgb_image)\n","\n","    plt.subplot(1, 4, 2)\n","    plt.title(\"Gloabl Coarse Output\")\n","    plt.imshow(coarse_output)\n","\n","    plt.subplot(1, 4, 3)\n","    plt.title(\"Local Fine Output\")\n","    plt.imshow(fine_output)\n","\n","    plt.subplot(1, 4, 4)\n","    plt.title(\"Ground Truth\")\n","    plt.imshow(depth_gt)\n","    plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEPQTdDeKqWE"},"source":[""],"execution_count":null,"outputs":[]}]}
>>>>>>> Stashed changes
